{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a10e85cc",
   "metadata": {},
   "source": [
    "## DPO Training with Unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc0a76a-c326-46fc-82bc-51ef6e6d8207",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "major_version, minor_version = torch.cuda.get_device_capability()\n",
    "# Must install separately since Colab has torch 2.2.1, which breaks packages\n",
    "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "if major_version >= 8:\n",
    "    # Use this for new GPUs like Ampere, Hopper GPUs (RTX 30xx, RTX 40xx, A100, H100, L40)\n",
    "    !pip install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes\n",
    "else:\n",
    "    # Use this for older GPUs (V100, Tesla T4, RTX 20xx)\n",
    "    !pip install --no-deps xformers trl peft accelerate bitsandbytes\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013485f6-f674-45fd-a60c-fe03533fd023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6389fdae-4051-48c1-bc69-bb888b3124a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One must patch the DPO Trainer first!\n",
    "from unsloth import PatchDPOTrainer\n",
    "PatchDPOTrainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143c804d-208e-4d7a-9890-ad8b9e7ae8ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a374434d-21ac-48ea-aa50-37ae087a0e28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 4096 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"./results2/checkpoint-1200\", # Choose ANY! eg mistralai/Mistral-7B-Instruct-v0.2\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9b06c7-4fd2-47bc-9a92-e5c52f8b7206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f659dd85-a6d5-464d-a02d-821511dab870",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_path= \"nbroad-v2.csv\"\n",
    "df = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc8a42d8-9b7f-463b-ae63-cbaab3d4b277",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_numbered_list(text):\n",
    "    final_text_paragraphs = [] \n",
    "    for line in text.split('\\n'):\n",
    "        # Split each line at the first occurrence of '. '\n",
    "        parts = line.split('. ', 1)\n",
    "        # If the line looks like a numbered list item, remove the numbering\n",
    "        if len(parts) > 1 and parts[0].isdigit():\n",
    "            final_text_paragraphs.append(parts[1])\n",
    "        else:\n",
    "            # If it doesn't look like a numbered list item, include the line as is\n",
    "            final_text_paragraphs.append(line)\n",
    "\n",
    "    return '  '.join(final_text_paragraphs)\n",
    "\n",
    "\n",
    "#trims LLM output to just the response\n",
    "def trim_to_response(text):\n",
    "    terminate_string = \"[/INST]\"\n",
    "    text = text.replace('</s>', '')\n",
    "    #just in case it puts things in quotes\n",
    "    text = text.replace('\"', '')\n",
    "    text = text.replace(\"'\", '')\n",
    "\n",
    "    last_pos = text.rfind(terminate_string)\n",
    "    return text[last_pos + len(terminate_string):] if last_pos != -1 else text\n",
    "\n",
    "#looks for response_start / returns only text that occurs after\n",
    "def extract_text_after_response_start(full_text):\n",
    "    parts = full_text.rsplit(response_start, 1)  # Split from the right, ensuring only the last occurrence is considered\n",
    "    if len(parts) > 1:\n",
    "        return parts[1].strip()  # Return text after the last occurrence of response_start\n",
    "    else:\n",
    "        return full_text  # Return the original text if response_start is not found\n",
    "\n",
    "    \n",
    "#trims text to requested number of sentences (or first LF or double-space sequence)\n",
    "def trim_to_first_x_sentences_or_lf(text, x):\n",
    "    if x <= 0:\n",
    "        return \"\"\n",
    "\n",
    "    # Any double-spaces dealt with as linefeed\n",
    "    text = text.replace(\"  \", \"\\n\")\n",
    "\n",
    "    # Split text at the first linefeed\n",
    "    text_chunks = text.split('\\n', 1)\n",
    "    first_chunk = text_chunks[0]\n",
    "\n",
    "    # Split the first chunk into sentences, considering the space after each period\n",
    "    sentences = [sentence.strip() for sentence in first_chunk.split('.') if sentence]\n",
    "\n",
    "    # If there's a linefeed, return the text up to the first linefeed\n",
    "    if len(text_chunks) > 1:\n",
    "        # Check if the first chunk has fewer sentences than x, and if so, just return it\n",
    "        if len(sentences) < x:\n",
    "            trimmed_text = first_chunk\n",
    "        else:\n",
    "            # Otherwise, trim to x sentences within the first chunk\n",
    "            trimmed_text = '. '.join(sentences[:x]).strip()\n",
    "    else:\n",
    "        # If there's no linefeed, determine if the number of sentences is less than or equal to x\n",
    "        if len(sentences) <= x:\n",
    "            trimmed_text = '. '.join(sentences).strip()  # Ensure space is preserved after periods\n",
    "        else:\n",
    "            # Otherwise, return the first x sentences, again ensuring space after periods\n",
    "            trimmed_text = '. '.join(sentences[:x]).strip()\n",
    "\n",
    "    # Add back the final period if it was removed and the text needs to end with a sentence.\n",
    "    if len(sentences) > 0 and not trimmed_text.endswith('.'):\n",
    "        trimmed_text += '.'\n",
    "\n",
    "    return trimmed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43401ff6-47cb-4744-88f5-3142218dedd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#original text prefix\n",
    "orig_prefix = \"Original Text:\"\n",
    "\n",
    "instruction_prefix = \"Instruction:\"\n",
    "\n",
    "#mistral \"response\"\n",
    "instruction = \"There are two sentences defined as Original Text and Re-written Text below. You will tell what new element was added or change in tone was made to improve it - with no references to the original.  You will avoid mentioning names of characters.  It is crucial no person, place or thing from the original text be mentioned.  For example - You will not say things like 'change the puppet show into a book report' - You would just say 'improve this text into a book report'.  If the original text mentions a specific idea, person, place, or thing - You will not mention it in your answer.  For example if there is a 'dog' or 'office' in the Original text - the word 'dog' or 'office' must not be in your response.\"\n",
    "#modified text prefix\n",
    "rewrite_prefix = \"Re-written Text:\"\n",
    "\n",
    "#provided as start of Mistral response (anything after this is used as the prompt)\n",
    "#providing this as the start of the response helps keep things relevant\n",
    "response_start = \"Answer: \"\n",
    "\n",
    "#added after response_start to prime mistral\n",
    "#\"Improve this\" or \"Improve this text\" resulted in non-answers.  \n",
    "#\"Improve this text by\" seems to product good results\n",
    "response_prefix = \"Improve this text by\"\n",
    "\n",
    "#well-scoring baseline text\n",
    "#thanks to: https://www.kaggle.com/code/rdxsun/lb-0-61\n",
    "base_line = 'Refine the following passage by emulating the writing style of [insert desired style here], with a focus on enhancing its clarity, elegance, and overall impact. Preserve the essence and original meaning of the text, while meticulously adjusting its tone, vocabulary, and stylistic elements to resonate with the chosen style.Please improve the following text using the writing style of, maintaining the original meaning but altering the tone, diction, and stylistic elements to match the new style.Enhance the clarity, elegance, and impact of the following text by adopting the writing style of , ensuring the core message remains intact while transforming the tone, word choice, and stylistic features to align with the specified style.' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec3e3d63-d91d-4e7e-9496-b45d2b9d032b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_prompt(instruction , original_text ,rewritten_text):\n",
    "  prompt=f\"<s>[INST] Instruction:\\n{instruction} \\nOriginal Text:\\n{original_text} \\nRe-written Text: \\n{rewritten_text}[/INST]\\nAnswer:\\n\"\n",
    "\n",
    "  \n",
    "  return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5aa168-c727-4f9b-b449-a2dede5b15a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_prompt_wo_answer_prefix(instruction , original_text ,rewritten_text):\n",
    "  prompt=f\"<s>[INST] Instruction:\\n{instruction} \\nOriginal Text:\\n{original_text} \\nRe-written Text: \\n{rewritten_text}[/INST]\"\n",
    "\n",
    "  \n",
    "  return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecb02d8-eecb-4ef0-aa4d-ee531f3a883f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = build_prompt(instruction ,df.iloc[1][\"original_text\"] ,df.iloc[1][\"rewritten_text\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1b8e2a-8180-40f8-9a93-4cbedbd9465e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['rejected'].notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fc0173-ec02-4957-94ab-abc96f77be42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    text = build_prompt(instruction ,row['original_text'], row['rewritten_text'])\n",
    "    inputs = tokenizer([text,], return_tensors = \"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens = 20, use_cache = True)\n",
    "    result_raw = tokenizer.batch_decode(outputs)\n",
    "    just_response = trim_to_response(result_raw[0])        \n",
    "    final_text = extract_text_after_response_start(just_response)\n",
    "    print(index)\n",
    "    df.at[index, 'rejected'] = final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9199a4-514d-4f78-98e8-a7c7fc46313f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    text = build_prompt_wo_answer_prefix(instruction ,row['original_text'], row['rewritten_text'])\n",
    "    df.at[index, 'prompt'] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66838390-f20a-47a2-b7fc-3309cac5571c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    df.at[index, 'chosen'] = \"\\nAnswer:\\n\" + row['chosen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67404f7f-c92a-4363-8838-6f3caba4d2f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ac8a2c-c37e-44fd-8501-0d8775b98fd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "df['rejected'].notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2cf046-ac40-4579-b0ec-dff2a3094a71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.iloc[:766]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5f8c64-ae72-4490-9678-043d29a157b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert to dataset object\n",
    "dataset = ds.dataset(pa.Table.from_pandas(df).to_batches())\n",
    "dataset = Dataset(pa.Table.from_pandas(df))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea38dff-e9f5-4208-98c6-5852f0445876",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2 = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 64, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 64,\n",
    "    lora_dropout = 0, # Currently only supports dropout = 0\n",
    "    bias = \"none\",    # Currently only supports bias = \"none\"\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683dfe52-377b-4bb9-825b-629951185b97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One must patch the DPO Trainer first!\n",
    "from unsloth import PatchDPOTrainer\n",
    "PatchDPOTrainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d904a3e-48dd-430e-b182-dbe428060e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb01d3d3-4d17-4645-84cd-a04f9965335f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from trl import DPOTrainer\n",
    "\n",
    "dpo_trainer = DPOTrainer(\n",
    "    model = model,\n",
    "    ref_model = None,\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_ratio = 0.1,\n",
    "        num_train_epochs = 20,\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate = 5e-6,\n",
    "        fp16 = not torch.cuda.is_bf16_supported(),\n",
    "        bf16 = torch.cuda.is_bf16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.0,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 42,\n",
    "        output_dir = \"dpo_output2\",\n",
    "    ),\n",
    "    beta = 0.1,\n",
    "    train_dataset = dataset,\n",
    "    # eval_dataset = raw_datasets[\"test\"],\n",
    "    tokenizer = tokenizer,\n",
    "    max_length = 1024,\n",
    "    max_prompt_length = 512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efb89a6-0c9d-4631-9f9e-d45d478b5ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40fd281-bad5-4b4d-b87b-eaa231329941",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dpo_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce0513f-4b1a-45fa-92fc-74665213a29c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e1261f-ae04-48ce-919c-27fe3fde20d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d11adb-b936-4fb9-a383-41abdeb25a3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Try model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22dd9afc-9d25-4166-926a-f4d1b53d5156",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,HfArgumentParser,TrainingArguments,pipeline, logging\n",
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
    "import os,torch\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6676cb9e-6b5b-4617-9991-c7ff57fb5b94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "peft_model = \"./dpo_output2/checkpoint-287\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af0c8a14-77ca-4991-a01a-724c362e2492",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec773bee9ca40dcaf5a59c5be67743a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(base_model , load_in_4bit=True, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a22a2338-5852-4ab1-b6fb-518269bf0a68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model.load_adapter(peft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc2fe0d8-f46e-4ab8-ae98-415c38f67aed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_prompt(instruction , original_text ,rewritten_text):\n",
    "  prompt=f\"<s>[INST] Instruction:\\n{instruction} \\nOriginal Text:\\n{original_text} \\nRe-written Text: \\n{rewritten_text}[/INST]\\nAnswer:\\n\"\n",
    "\n",
    "  \n",
    "  return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d75064db-7b14-4096-acac-51414315d28a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = build_prompt(instruction ,df.iloc[343][\"original_text\"] ,df.iloc[343][\"rewritten_text\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "122920f1-f381-4242-972f-40e0142761a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    inputs = tokenizer([text,], return_tensors = \"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens = 20, use_cache = True)\n",
    "    result_raw = tokenizer.batch_decode(outputs)\n",
    "    just_response = trim_to_response(result_raw[0])        \n",
    "    final_text = extract_text_after_response_start(just_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7fa0b93-f5a8-451c-af69-b940dcfe35ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAnswer:\\nRewrite the essay as if it takes place in feudal Japan during the Sengoku'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bcbe854-abd1-4118-90fa-3dc9c6c116be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rewrite the story as a time-travel fantasy set in Feudal Japan'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[343]['rewrite_prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a836a67-84a0-4f74-bd8b-0261b2a1f4b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./dpo_output2/checkpoint-191/tokenizer.model [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-191/rng_state.pth [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-191/trainer_state.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-191/README.md [Content-Type=text/markdown]...\n",
      "- [4 files][594.6 KiB/594.6 KiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file://./dpo_output2/checkpoint-191/training_args.bin [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-191/tokenizer_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-191/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-191/adapter_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-191/special_tokens_map.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-191/tokenizer.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-191/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "Copying file://./dpo_output2/checkpoint-191/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-574/tokenizer.model [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-574/rng_state.pth [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-574/trainer_state.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-574/README.md [Content-Type=text/markdown]...\n",
      "Copying file://./dpo_output2/checkpoint-574/training_args.bin [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-574/tokenizer_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-574/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-574/adapter_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-574/special_tokens_map.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-574/tokenizer.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-574/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-574/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1819/tokenizer.model [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1819/rng_state.pth [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1819/trainer_state.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1819/README.md [Content-Type=text/markdown]...\n",
      "Copying file://./dpo_output2/checkpoint-1819/training_args.bin [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1819/tokenizer_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1819/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-1819/adapter_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1819/special_tokens_map.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1819/tokenizer.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1819/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-1819/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1053/tokenizer.model [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1053/rng_state.pth [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1053/trainer_state.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1053/README.md [Content-Type=text/markdown]...\n",
      "Copying file://./dpo_output2/checkpoint-1053/training_args.bin [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1053/tokenizer_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1053/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-1053/adapter_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1053/special_tokens_map.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1053/tokenizer.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1053/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-1053/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1723/tokenizer.model [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1723/rng_state.pth [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1723/trainer_state.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1723/README.md [Content-Type=text/markdown]...\n",
      "Copying file://./dpo_output2/checkpoint-1723/training_args.bin [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1723/tokenizer_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1723/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-1723/adapter_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1723/special_tokens_map.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1723/tokenizer.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1723/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-1723/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1532/tokenizer.model [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1532/rng_state.pth [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1532/trainer_state.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1532/README.md [Content-Type=text/markdown]...\n",
      "Copying file://./dpo_output2/checkpoint-1532/training_args.bin [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1532/tokenizer_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1532/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-1532/adapter_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1532/special_tokens_map.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1532/tokenizer.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1532/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-1532/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/runs/Apr15_21-59-28_instance-20240409-173451/events.out.tfevents.1713218375.instance-20240409-173451 [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/runs/Apr15_21-51-36_instance-20240409-173451/events.out.tfevents.1713217916.instance-20240409-173451 [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-478/tokenizer.model [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-478/rng_state.pth [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-478/trainer_state.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-478/README.md [Content-Type=text/markdown]...\n",
      "Copying file://./dpo_output2/checkpoint-478/training_args.bin [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-478/tokenizer_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-478/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-478/adapter_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-478/special_tokens_map.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-478/tokenizer.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-478/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-478/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1900/tokenizer.model [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1900/rng_state.pth [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1900/trainer_state.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1900/README.md [Content-Type=text/markdown]...\n",
      "Copying file://./dpo_output2/checkpoint-1900/training_args.bin [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1900/tokenizer_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1900/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-1900/adapter_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1900/special_tokens_map.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1900/tokenizer.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1900/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-1900/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-383/tokenizer.model [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-383/rng_state.pth [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-383/trainer_state.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-383/README.md [Content-Type=text/markdown]...\n",
      "Copying file://./dpo_output2/checkpoint-383/training_args.bin [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-383/tokenizer_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-383/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-383/adapter_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-383/special_tokens_map.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-383/tokenizer.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-383/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-383/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-95/tokenizer.model [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-95/rng_state.pth [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-95/trainer_state.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-95/README.md [Content-Type=text/markdown]...\n",
      "Copying file://./dpo_output2/checkpoint-95/training_args.bin [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-95/tokenizer_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-95/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-95/adapter_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-95/special_tokens_map.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-95/tokenizer.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-95/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-95/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-287/tokenizer.model [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-287/rng_state.pth [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-287/trainer_state.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-287/README.md [Content-Type=text/markdown]...\n",
      "Copying file://./dpo_output2/checkpoint-287/training_args.bin [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-287/tokenizer_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-287/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-287/adapter_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-287/special_tokens_map.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-287/tokenizer.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-287/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-287/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-670/tokenizer.model [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-670/rng_state.pth [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-670/trainer_state.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-670/README.md [Content-Type=text/markdown]...\n",
      "Copying file://./dpo_output2/checkpoint-670/training_args.bin [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-670/tokenizer_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-670/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-670/adapter_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-670/special_tokens_map.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-670/tokenizer.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-670/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-670/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1436/tokenizer.model [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1436/rng_state.pth [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1436/trainer_state.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1436/README.md [Content-Type=text/markdown]...\n",
      "Copying file://./dpo_output2/checkpoint-1436/training_args.bin [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1436/tokenizer_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1436/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-1436/adapter_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1436/special_tokens_map.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1436/tokenizer.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1436/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-1436/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1244/tokenizer.model [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1244/rng_state.pth [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1244/trainer_state.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1244/README.md [Content-Type=text/markdown]...\n",
      "Copying file://./dpo_output2/checkpoint-1244/training_args.bin [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1244/tokenizer_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1244/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-1244/adapter_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1244/special_tokens_map.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1244/tokenizer.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1244/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-1244/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-957/tokenizer.model [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-957/rng_state.pth [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-957/trainer_state.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-957/README.md [Content-Type=text/markdown]...\n",
      "Copying file://./dpo_output2/checkpoint-957/training_args.bin [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-957/tokenizer_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-957/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-957/adapter_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-957/special_tokens_map.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-957/tokenizer.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-957/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-957/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-766/tokenizer.model [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-766/rng_state.pth [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-766/trainer_state.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-766/README.md [Content-Type=text/markdown]...\n",
      "Copying file://./dpo_output2/checkpoint-766/training_args.bin [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-766/tokenizer_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-766/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-766/adapter_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-766/special_tokens_map.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-766/tokenizer.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-766/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-766/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1340/tokenizer.model [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1340/rng_state.pth [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1340/trainer_state.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1340/README.md [Content-Type=text/markdown]...\n",
      "Copying file://./dpo_output2/checkpoint-1340/training_args.bin [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1340/tokenizer_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1340/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-1340/adapter_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1340/special_tokens_map.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1340/tokenizer.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1340/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-1340/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1149/tokenizer.model [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1149/rng_state.pth [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1149/trainer_state.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1149/README.md [Content-Type=text/markdown]...\n",
      "Copying file://./dpo_output2/checkpoint-1149/training_args.bin [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1149/tokenizer_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1149/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-1149/adapter_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1149/special_tokens_map.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1149/tokenizer.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1149/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-1149/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-861/tokenizer.model [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-861/rng_state.pth [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-861/trainer_state.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-861/README.md [Content-Type=text/markdown]...\n",
      "Copying file://./dpo_output2/checkpoint-861/training_args.bin [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-861/tokenizer_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-861/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-861/adapter_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-861/special_tokens_map.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-861/tokenizer.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-861/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-861/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1627/tokenizer.model [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1627/rng_state.pth [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1627/trainer_state.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1627/README.md [Content-Type=text/markdown]...\n",
      "Copying file://./dpo_output2/checkpoint-1627/training_args.bin [Content-Type=application/octet-stream]...\n",
      "Copying file://./dpo_output2/checkpoint-1627/tokenizer_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1627/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-1627/adapter_config.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1627/special_tokens_map.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1627/tokenizer.json [Content-Type=application/json]...\n",
      "Copying file://./dpo_output2/checkpoint-1627/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./dpo_output2/checkpoint-1627/adapter_model.safetensors [Content-Type=application/octet-stream]...\n",
      "/ [242 files][ 10.4 GiB/ 10.4 GiB]  101.6 MiB/s                                 \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "\n",
      "Operation completed over 242 objects/10.4 GiB.                                   \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp -r ./dpo_output2 gs://artificialintelligence-393314/llm_finetuned/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ed561c-2ab1-4555-a19d-9cd78a6f0e07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu121.m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu121:m119"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
